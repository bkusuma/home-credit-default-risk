{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "from category_encoders import HashingEncoder\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, RocCurveDisplay, PrecisionRecallDisplay\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import sys\n",
    "src_path = '../src'\n",
    "sys.path.insert(0, src_path)\n",
    "from eval_classification import eval_classification\n",
    "del sys.path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_prepend = \"../..\"\n",
    "input_path = \"/kaggle/input/home-credit-default-risk/\"\n",
    "# kaggle_notebook_input_path = \"/kaggle/input/home-credit-default-risk/\"\n",
    "\n",
    "# con = sqlite3.connect(local_prepend + input_path + \"home-credit-default-risk.sqlite\") # connect to database\n",
    "# pd.read_csv(local_prepend + input_path + \"application_train.csv\").to_sql(\"application_train\", con, if_exists='append', index=False, index_label=\"SK_ID_CURR\")\n",
    "\n",
    "application_train = pd.read_csv(local_prepend + input_path + \"application_train.csv\")\n",
    "\n",
    "# bureau_balance = pd.read_csv(local_prepend + input_path + \"bureau_balance.csv\")\n",
    "bureau = pd.read_csv(local_prepend + input_path + \"bureau.csv\")\n",
    "credit_card_balance = pd.read_csv(local_prepend + input_path + \"credit_card_balance.csv\")\n",
    "# installments_payments = pd.read_csv(local_prepend + input_path + \"installments_payments.csv\")\n",
    "POS_CASH_balance = pd.read_csv(local_prepend + input_path + \"POS_CASH_balance.csv\")\n",
    "previous_application = pd.read_csv(local_prepend + input_path + \"previous_application.csv\")\n",
    "\n",
    "# Description of columns in provided datasets\n",
    "# HomeCredit_columns_description = pd.read_csv(local_prepend + input_path + \"HomeCredit_columns_description.csv\", encoding = \"latin\")\n",
    "\n",
    "# # Test Data for later use\n",
    "# application_test = pd.read_csv(local_prepend + input_path + \"application_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train = pd.merge(application_train, bureau, how=\"left\", on=\"SK_ID_CURR\")\n",
    "application_train = application_train.drop_duplicates(subset=[\"SK_ID_CURR\"])\n",
    "application_train = pd.merge(application_train, previous_application, how=\"left\", on=\"SK_ID_CURR\")\n",
    "application_train = application_train.drop_duplicates(subset=[\"SK_ID_CURR\"])\n",
    "application_train = pd.merge(application_train, POS_CASH_balance, how=\"left\", on=\"SK_ID_CURR\")\n",
    "application_train = application_train.drop_duplicates(subset=[\"SK_ID_CURR\"])\n",
    "application_train = pd.merge(application_train, credit_card_balance, how=\"left\", on=\"SK_ID_CURR\")\n",
    "application_train = application_train.drop_duplicates(subset=[\"SK_ID_CURR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving preprocessor for future use\n",
    "to_save = {\"preprocessor\" : preprocessor,\n",
    "           \"porch_func\" : porch_func}\n",
    "filename = \"preprocessor.joblib\"\n",
    "\n",
    "joblib.dump(to_save, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
